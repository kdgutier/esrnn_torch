{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.M4_data import prepare_M4_data\n",
    "from src.M4_experiment import plot_model_prediction, evaluate_model_prediction\n",
    "from src.ESRNN import ESRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>7407.412314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1970-01-03</td>\n",
       "      <td>7528.566074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1970-01-04</td>\n",
       "      <td>7374.709225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>7395.514848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1970-01-06</td>\n",
       "      <td>7654.007989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1970-01-22</td>\n",
       "      <td>7212.253565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1970-01-23</td>\n",
       "      <td>7246.218675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1970-01-24</td>\n",
       "      <td>7178.380550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1970-01-25</td>\n",
       "      <td>7182.867128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1970-01-26</td>\n",
       "      <td>7171.501598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds            y\n",
       "0         Q1 1970-01-02  7407.412314\n",
       "1         Q1 1970-01-03  7528.566074\n",
       "2         Q1 1970-01-04  7374.709225\n",
       "3         Q1 1970-01-05  7395.514848\n",
       "4         Q1 1970-01-06  7654.007989\n",
       "..       ...        ...          ...\n",
       "70        Q3 1970-01-22  7212.253565\n",
       "71        Q3 1970-01-23  7246.218675\n",
       "72        Q3 1970-01-24  7178.380550\n",
       "73        Q3 1970-01-25  7182.867128\n",
       "74        Q3 1970-01-26  7171.501598\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df, y_train_df, X_test_df, y_test_df = prepare_M4_data('Quarterly', num_obs=3) #, num_obs=5\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast self.init_seas tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]])\n",
      "fast self.sms tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "=============== Training ESRNN  ===============\n",
      "\n",
      "fast lev_sms.size() torch.Size([3])\n",
      "fast seas_sms.size() torch.Size([3])\n",
      "fast init_seas.size() torch.Size([3, 1])\n",
      "fast init_seas \n",
      " tensor([[1.6487],\n",
      "        [1.6487],\n",
      "        [1.6487]], grad_fn=<ExpBackward>)\n",
      "fast lev_sms \n",
      " tensor([0.6225, 0.6225, 0.6225], grad_fn=<SelectBackward>)\n",
      "fast seas_sms \n",
      " tensor([0.6225, 0.6225, 0.6225], grad_fn=<SelectBackward>)\n",
      "========= Epoch 0 finished =========\n",
      "Training time: 0.23358\n",
      "Training loss: 0.29354000091552734\n",
      "fast lev_sms.size() torch.Size([3])\n",
      "fast seas_sms.size() torch.Size([3])\n",
      "fast init_seas.size() torch.Size([3, 1])\n",
      "fast init_seas \n",
      " tensor([[1.6484],\n",
      "        [1.6483],\n",
      "        [1.6487]], grad_fn=<ExpBackward>)\n",
      "fast lev_sms \n",
      " tensor([0.6222, 0.6222, 0.6222], grad_fn=<SelectBackward>)\n",
      "fast seas_sms \n",
      " tensor([0.6222, 0.6222, 0.6222], grad_fn=<SelectBackward>)\n",
      "OWA: 22.221 \n",
      "SMAPE: 39.67 \n",
      "MASE: 21.54 \n",
      "Train finished! \n",
      "\n",
      "self.init_seas Parameter containing:\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], requires_grad=True)\n",
      "self.lev_sms Parameter containing:\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], requires_grad=True)\n",
      "self.seas_sms Parameter containing:\n",
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], requires_grad=True)\n",
      "=============== Training ESRNN  ===============\n",
      "\n",
      "lev_sms.size() torch.Size([3])\n",
      "seas_sms.size() torch.Size([3])\n",
      "init_seas.size() torch.Size([3, 1])\n",
      "init_seas \n",
      " tensor([[1.6487],\n",
      "        [1.6487],\n",
      "        [1.6487]], grad_fn=<StackBackward>)\n",
      "lev_sms \n",
      " tensor([0.6225, 0.6225, 0.6225], grad_fn=<SigmoidBackward>)\n",
      "seas_sms \n",
      " tensor([0.6225, 0.6225, 0.6225], grad_fn=<SigmoidBackward>)\n",
      "========= Epoch 0 finished =========\n",
      "Training time: 0.21621\n",
      "Training loss: 0.2989499866962433\n",
      "lev_sms.size() torch.Size([3])\n",
      "seas_sms.size() torch.Size([3])\n",
      "init_seas.size() torch.Size([3, 1])\n",
      "init_seas \n",
      " tensor([[1.6486],\n",
      "        [1.6480],\n",
      "        [1.6487]], grad_fn=<StackBackward>)\n",
      "lev_sms \n",
      " tensor([0.6222, 0.6222, 0.6222], grad_fn=<SigmoidBackward>)\n",
      "seas_sms \n",
      " tensor([0.6222, 0.6222, 0.6222], grad_fn=<SigmoidBackward>)\n",
      "OWA: 23.563 \n",
      "SMAPE: 42.931 \n",
      "MASE: 22.433 \n",
      "Train finished! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## Weekly\n",
    "# esrnn = ESRNN(max_epochs=4, batch_size=4, dilations=[[1, 4], [52]], rnn_weight_decay=0.5, freq_of_test=1)\n",
    "\n",
    "## Quarterly\n",
    "# esrnn = ESRNN(max_epochs=1, batch_size=3, rnn_weight_decay=0.5, freq_of_test=1)\n",
    "\n",
    "## Daily\n",
    "# esrnn = ESRNN(max_epochs=2, batch_size=16, learning_rate=3e-4, per_series_lr_multip=1.5,\n",
    "#               gradient_eps=1e-6, level_variability_penalty=100,\n",
    "#               dilations=[[1,7],[28]], add_nl_layer=True,\n",
    "#               seasonality=[7], input_size=7, output_size=14)\n",
    "\n",
    "# Debugging Quarterly\n",
    "with torch.autograd.detect_anomaly():\n",
    "    esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=3, state_hsize=4,\n",
    "                  seasonality=[1], input_size=3, output_size=8, dilations=[[1, 2]],\n",
    "                  rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM',\n",
    "                  gradient_clipping_threshold=2000)\n",
    "    esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "    \n",
    "# Debugging Quarterly\n",
    "with torch.autograd.detect_anomaly():\n",
    "    esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=3, state_hsize=4,\n",
    "                  seasonality=[1, 2], input_size=3, output_size=8, dilations=[[1, 2]],\n",
    "                  rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM',\n",
    "                  gradient_clipping_threshold=2000)\n",
    "    esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "    \n",
    "## Debugging Yearly\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=4, max_periods=1, batch_size=3, state_hsize=4,\n",
    "#                   seasonality=[24, 168], input_size=3, output_size=6, dilations=[[1, 2]],\n",
    "#                   rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM')\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "\n",
    "## Debugging Hourly\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=4, max_periods=1, batch_size=3, state_hsize=4,\n",
    "#                   seasonality=[24, 168], input_size=3, output_size=48, dilations=[[1, 2]],\n",
    "#                   rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM')\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_prediction(y_train_df, X_test_df, y_test_df, model=esrnn, u_id='Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn.evaluate_model_prediction(y_train_df, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M4 eval\n",
    "#(0.778*(23.0/100) + 0.847*(24.0/100) + 0.836*(48.0/100) + 0.920*(5.0/100))\n",
    "#(13.176*() + 9.679*() + 12.126*())\n",
    "#(14.42*(23.0/(23+24+48)) + 10.09*(24.0/(23+24+48)) + 10.81*(48.0/(23+24+48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hyperpar_tunning_m4 import parse_grid_search\n",
    "from src.utils_visualization import plot_grid_cat_distributions\n",
    "\n",
    "gs_df = parse_grid_search('Quarterly')\n",
    "# plot_cat_distributions(df=gs_df, cat='learning_rate', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='add_nl_layer', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='rnn_weight_decay', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='per_series_lr_multip', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='batch_size', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='training_percentile', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='dilations', var='min_owa')\n",
    "\n",
    "gs_df['early_stopping'] = gs_df.min_epoch < gs_df.max_epochs\n",
    "plot_grid_cat_distributions(gs_df, var = 'min_owa',\n",
    "                            cats=['learning_rate', 'per_series_lr_multip', 'batch_size', 'early_stopping',\n",
    "                                  'rnn_weight_decay', 'training_percentile', 'add_nl_layer', 'dilations'])\n",
    "# plot_grid_cat_distributions(gs_df, var = 'owa',\n",
    "#                             cats=['learning_rate', 'per_series_lr_multip', 'batch_size', 'early_stopping',\n",
    "#                                   'rnn_weight_decay', 'training_percentile', 'add_nl_layer', 'dilations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df = parse_grid_search('Monthly')\n",
    "gs_df.min_owa.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df = parse_grid_search('Quarterly')\n",
    "gs_df.min_owa.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = esrnn.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ver.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esrnn_torch",
   "language": "python",
   "name": "esrnn_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
